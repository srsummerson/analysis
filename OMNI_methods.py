import numpy as np
import scipy as sp
from scipy import signal
import re
from neo import io
import pandas as pd
from matplotlib import pyplot as plt
import matplotlib as mpl
from matplotlib import mlab
import tables


def convert_OMNI(filename, **kwargs):
	'''
	This method converts csv files saved using the OMNI device to a pandas DataFrame for easy
	analysis in Python.

	Input:
		- filename: string containing the file path for a csv file saved with the OMNI device
	
		
	Output:
		- data: pandas DataFrame, M rows x N columns, M = number of data points, N = number of channels + 1, 
				first N -1 columns corresponds to data from the differnt channels while the Nth column 
				contains the timestamps 

	'''
	data = pd.read_csv(filename,sep=',',header=None,skiprows=[0,1])
	time_samps, num_col = data.shape
	crc_flag = np.array(data[:][0])
	ind_crc_pass = [ind for ind in range(0,len(crc)) if crc[ind]==170]

	channel_data = np.zeros([len(ind_crc_pass),num_col-3])  # 3 fewer columns since one is crv flag, one is ramp, and one is time samples
	
	for col in range(0,num_col-3):
		channel_data[:,col] = data[ind_crc_pass][col+1]
	timestamps = np.array(data[ind_crc_pass][num_col-1])
	counter_ramp = np.array(data[ind_crc_pass][num_col-2])

	corrected_channel_data = [data[0,:]]
	corrected_counter = [counter_ramp[0]]
	num_cycle = 0

	for i in range(1,len(counter_ramp)):
		diff = counter_ramp[i] - counter_ramp[i-1]
		if (diff==1):
			corrected_channel_data.append(data[i,:])
			corrected_counter.append(counter_ramp[i] + num_cycle*(2**16))
		elif (diff == -2**16 +1):
			num_cycle += 1
			corrected_channel_data.append(data[i,:])
			corrected_counter.append(counter_ramp[i] + num_cycle*(2**16))
		else:
			num_samples_insert = diff - 1.
			corrected_counter.append((counter_ramp[i-1] + range(1,diff) + num_cycle*(2**16)).tolist())

	return channel_data, timestamps, crc_flag, counter_ramp


def plotRawLFPTraces(data, **kwargs):
	'''
	This method plots the raw LFP data for all channels or a subset of channels in a single plot 
	for easy viewing. Data is normalized to have zero DC component. Spacing between traces is determined by 
	the max standard deviation across all channels.

	Input:
		- data: numpy array, as generated by the convert_OMNI method
	Optional input:
		- channs: list of channels to be plotted
		- filter_data: True/False if low-pass filter is applied to data, default is False
	'''
	num_channs = data.shape[1]
	 		
	if kwargs:
		channs = kwargs['channs']
	else:
		channs = range(1,num_channs,1) 	# recall one column is for timestamps, not channel data

	channs = [(chann - 1) for chann in channs]  # channel numbers are offset by 1 from index values

	'''
	if filter_data:
		cutoff_f = 100
		cutoff_f = cutoff_f/(1000./2)  # sampling rate is 1000 Hz
		num_taps = 100
		lpf = signal.firwin(num_taps,cutoff_f,window='hamming')
		for chann in channs:
			data[:][chann] = signal.lfilter(lpf,1,data[:][chann])
	'''

	mean_vec = np.mean(data[:,channs], axis = 0)
	std_vec = np.std(data[:,channs], axis = 0)

	for i, chann in enumerate(channs):
		test_above_thres = np.ravel(np.nonzero(np.greater(data[:,chann],mean_vec[i] + 8*std_vec[i])))
		test_below_thres = np.ravel(np.nonzero(np.less(data[:,chann],mean_vec[i] - 4*std_vec[i])))
		ind_to_be_corrected = np.append(test_above_thres, test_below_thres)
		ind_to_be_corrected = [ind for ind in ind_to_be_corrected]
		for ind in ind_to_be_corrected:
			if ind + 1 < data.shape[0]:
				data[ind,chann] = (data[ind-1, chann] + data[ind+1,chann])/2.
			else:
				data[ind,chann] = data[ind-1, chann]

	mean_vec = np.mean(data[:,channs], axis = 0)
	std_vec = np.std(data[:,channs], axis = 0)
	trace_dist = 0.25*np.max([std_vec])  # don't include std of time stamps when 

	times = data[:,num_channs-1]

	plt.figure()
	cmap = mpl.cm.brg
	for i, chann in enumerate(channs):
		plt.plot(times[:5000],data[:5000,chann] - mean_vec[i] + i*trace_dist,color=cmap(i/float(len(channs))), label=str(chann))
	plt.xlabel('Time (s)')
	plt.title('LFP Traces')
	plt.legend()

	plt.show()

	return

def get_stim_sync_sig(tdt_tank):
	r = io.TdtIO(dirname = tdt_tank)
	bl = r.read_block(lazy=False,cascade=True)

	for sig in bl.segments[0].analogsignals:
		if (sig.name == 'StWv 1'):
			# Signal is output of stimulator monitor recording voltage on channel stimulation is delivered on
			stim_monitor = np.ravel(sig)
		if (sig.name == 'StWv 2'):
			# Stimulation signal used: this is the base stimulation signal that is turned on/off
			stim_signal = np.ravel(sig)
		if (sig.name == 'StWv 4'):
			# Trigger signal for stimulation. High is ON, Low is OFF.
			stim_on_trig = np.ravel(sig)
		if (sig.name == 'StWv 3'):
			# Control signal for stimulator. When stim_on_trig = 1, this signal equals stim_signal
			stim_delivered = np.ravel(sig)
			stwv_samprate = sig.sampling_rate.item()

	return stim_signal, stim_on_trig, stim_delivered, stwv_samprate


def test_convert_OMNI(data, **kwargs):
	
	#data = pd.read_csv(filename,sep=',',header=None,skiprows=[0,1])
	data = np.array(data)
	time_samps, num_col = data.shape
	crc_flag = np.array(data[:,0])
	ind_crc_pass = [ind for ind in range(0,len(crc_flag)) if crc_flag[ind]==170]

	channel_data = np.zeros([len(ind_crc_pass),num_col-3])  # 3 fewer columns since one is crv flag, one is ramp, and one is time samples
	
	for col in range(0,num_col-3):
		channel_data[:,col] = data[ind_crc_pass,col+1]
	timestamps = data[ind_crc_pass,num_col-1]
	counter_ramp = data[ind_crc_pass,num_col-2]

	corrected_channel_data = channel_data[0,:]
	corrected_counter = [counter_ramp[0]]
	num_cycle = 0

	for i in range(1,len(counter_ramp)):
	#for i in range(1,17000):
		diff = counter_ramp[i] - counter_ramp[i-1]
		diff = int(diff)
		if (i % 1000 == 0):
			print i, diff
		elif (diff > 1):
			print i, diff
		if (diff==1):
			corrected_counter.append(counter_ramp[i] + num_cycle*(2**16))
			corrected_channel_data = np.vstack([corrected_channel_data,channel_data[i,:]])
		elif (diff == -2**16 +1):
			num_cycle += 1
			corrected_counter.append(counter_ramp[i] + num_cycle*(2**16))
			corrected_channel_data = np.vstack([corrected_channel_data,channel_data[i,:]])
		else:
			num_samples_insert = diff - 1.
			corrected_counter.extend((counter_ramp[i-1] + range(1,diff+1) + num_cycle*(2**16)).tolist())
			print len(counter_ramp[i-1] + range(1,diff+1) + num_cycle*(2**16))
			print num_samples_insert
			inter_mat = np.zeros([num_samples_insert+1,num_col-3])
			for j in range(0,num_col-3):
				y = np.interp(range(1,diff),[0, diff], [channel_data[i-1,j], channel_data[i,j]])
				y = np.append(y,channel_data[i,j])
				inter_mat[:,j] = y
			corrected_channel_data = np.vstack([corrected_channel_data,inter_mat])
		

	return corrected_counter, corrected_channel_data


filename_prefix = 'C:/Users/Samantha Summerson/Dropbox/Carmena Lab/OMNI_Device/Data/streams7_20/'
filename = filename_prefix + '20160720-163020.csv'
#filename = filename_prefix + '20160720-171300.csv'
#filename = filename_prefix + '20160720-174338.csv'
data = pd.read_csv(filename,sep=',',header=None,skiprows=[0,1])
print "Data read."
corrected_counter, corrected_channel_data = test_convert_OMNI(data)

